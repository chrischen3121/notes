#+TITLE: Asyncio
#+OPTIONS: H:3 toc:2 num:2 ^:nil
#+AUTHOR: ChrisChen
#+EMAIL: ChrisChen3121@gmail.com
* Walk-Through
  #+begin_src python
    import asyncio
    import time

    async def main():
        print(f"{time.ctime()} Hello!")
        await asyncio.sleep(1.0)
        print(f"{time.ctime()} Goodbye!")

    loop = asyncio.get_event_loop()
    task = loop.create_task(main())

    loop.run_until_complete(task) # asyncio.run() calls run_until_complete()
    # all other tasks scheduled on the loop will also run while the loop is running.

    # graceful exit
    pending = asyncio.all_tasks(loop=loop)
    for task in pending:
        task.cancel()
    group = asyncio.gather(*pending, return_exceptions=True)
    loop.run_until_complete(group)
    loop.close() # A stopped loop can be restarted, but a closed loop is gone for good.
    # asyncio.run() will do all of the cancelling, gathering, and waiting for pending tasks to finish up.
  #+end_src

  - ~asyncio.run()~ will do all of the cancelling, gathering, and waiting for pending tasks to finish up.
  - ~asyncio.run()~ creates a new event loop every time you call it.

** Run /blocking/ Functions
  Uses ~loop.run_in_executor~
  #+begin_src python
    import time
    import asyncio


    def blocking():
        time.sleep(1)
        print(f"{time.ctime()} from a thread!")


    async def main():
        print(f"{time.ctime()} Hello!")
        await asyncio.sleep(1.0)
        print(f"{time.ctime()} Goodbye!")


    loop = asyncio.get_event_loop()
    task = loop.create_task(main())

    loop.run_in_executor(None, blocking) # set None to use a new executor instead of a default
    loop.run_until_complete(task)

    pending = asyncio.all_tasks(loop=loop)
    # ....
  #+end_src

  - ~run_in_executor()~ schedules the executor task to run (it returns a Future).
  - The executor task will begin executing only after ~run_until_complete()~ is called.
  - ~run_in_executor()~ /tasks/ are not in /pending/ tasks. This will be true of for any call that returns a *Future* rather than a *Task*.

* *Startup and Shutdown*
** Startup
   Standard way is to have a ~main()~ coroutine function and call it with ~asyncio.run()~

** Shut Down Gracefully
   1. Collect all the still-pending task objects.
   1. Cancel these tasks (you may choose to handle ~asyncio.CancelledError~ in a try/except within the body of the coroutine function).
   1. Gather all these tasks into a group task.
   1. Use ~run_until_complete()~ on the group task to wait for them to finish. i.e. let the CancelledError be raised and dealt with.

   - ~asyncio.run()~ performs these actions for you
     - Internally within ~asyncio.run()~, the raised KeyboardInterrupt effectively unblocks a loop.run_until_complete() call and allows the subsequent shutdown sequence to happen.


*** Details
   #+begin_src python
     import asyncio

     loop = asyncio.get_event_loop()
     pendings = asyncio.all_tasks()
     group = asyncio.gather(*pendings, return_exceptions=True)
     results = loop.run_until_complete(group)
     print(f'Results: {results}')
     loop.close()
   #+end_src

*** Tiny PyPI Package ~aiorun~
    https://github.com/cjrh/aiorun

*** Deal with Signals
   - SIGINT: KeyboardInterrupt corresponds to the SIGINT signal
   - SIGTERM: default signal when you use the kill command in a Unix shell
   #+begin_src python
     import asyncio
     from signal import SIGINT, SIGTERM

     async def main():
         try:
             while True:
                 print("<Your app is running>")
                 await asyncio.sleep(1)
         except asyncio.CancelledError:
             for i in range(3):
                 print("<Your app is shutting down...>")
                 await asyncio.sleep(1)

     def handler(sig):
         loop.stop()
         print(f"Got signal: {sig!s}, shutting down.")
         loop.remove_signal_handler(SIGTERM)
         loop.add_signal_handler(SIGINT, lambda: None)


     if __name__ == "__main__":
         loop = asyncio.get_event_loop()
         for sig in (SIGTERM, SIGINT):
             loop.add_signal_handler(sig, handler, sig)
         loop.create_task(main())
         loop.run_forever()
         tasks = asyncio.all_tasks(loop=loop)
         for t in tasks:
             t.cancel()
         group = asyncio.gather(*tasks, return_exceptions=True)
         loop.run_until_complete(group)
         loop.close()
   #+end_src
   - After you receive the first shutdown signal, you want to simply ignore any new signals until exit.
   - Simplify with ~asyncio.run()~
   #+begin_src python
     import asyncio
     from signal import SIGINT, SIGTERM


     async def main():
         loop = asyncio.get_running_loop()
         # asyncio.run() takes control of the event loop startup, our first opportunity
         # to change signal handling behavior will be in the main() function.
         for sig in (SIGTERM, SIGINT):
             loop.add_signal_handler(sig, handler, sig)
         try:
             while True:
                 print("<Your app is running>")
                 await asyncio.sleep(1)
         except asyncio.CancelledError:
             for i in range(3):
                 print("<Your app is shutting down...>")
                 await asyncio.sleep(1)

     def handler(sig):
         loop = asyncio.get_running_loop()
         for task in asyncio.all_tasks(loop=loop):
             task.cancel()
         print(f'Got signal: {sig!s}, shutting down.')
         loop.remove_signal_handler(SIGTERM)
         loop.add_signal_handler(SIGINT, lambda: None)

     if __name__ == '__main__':
         asyncio.run(main())

   #+end_src

*** Waiting for the Executor During Shutdown
    In *Python 3.9*, the asyncio.run() function has been improved to correctly wait for executor shutdown
    - Option 1: wrap the executor call inside a coroutine
    #+begin_src python
      def blocking():
          time.sleep(2.0)

      async def main():
          loop = asyncio.get_running_loop()
          future = loop.run_in_executor(None, blocking)
          try:
              await asyncio.sleep(1.0)
          finally:
              await future

      asyncio.run(main())
    #+end_src
    - Option 2: add the executor future to the gathered tasks
    #+begin_src python
      async def main():
          loop = asyncio.get_running_loop()
          future = loop.run_in_executor(None, blocking)
          asyncio.create_task(make_coro(future))
          await asyncio.sleep(1.0)

      asyncio.run(main())
    #+end_src
    - Option 3: bring your own loop and your own executor
    #+begin_src python
      async def main():
          await asyncio.sleep(1.0)
          loop.stop()

      def blocking():
          time.sleep(2.0)

      if __name__ == '__main__':
          loop = asyncio.get_event_loop()
          executor = ThreadPoolExecutor()
          loop.set_default_executor(executor)
          loop.create_task(main())
          future = loop.run_in_executor(None, blocking)
          try:
              loop.run_forever()
          except KeyboardInterrupt:
              print('Cancelled')
          tasks = asyncio.all_tasks(loop=loop)
          for t in tasks:
              t.cancel()
          group = asyncio.gather(*tasks, return_exceptions=True)
          loop.run_until_complete(group)
          executor.shutdown(wait=True)
          loop.close()
    #+end_src
* Async Infrastructure
** Hierarchy View
   | Concept                | Implementation                          |
   |------------------------+-----------------------------------------|
   | Tools                  | asyncio.Queue                           |
   | Subprocesses & threads | run_in_executor(), asyncio.subprocess   |
   | Tasks                  | asyncio.Task, asyncio.create_task()     |
   | Futures                | asyncio.Future                          |
   | Event loop             | asyncio.run(), BaseEventLoop            |
   | Coroutines             | async def, async with, async for, await |

   - Network I/O
   | Concept                | Implementation                                                                |
   |------------------------+-------------------------------------------------------------------------------|
   | Network: streams       | StreamReader, StreamWriter, asyncio.open_connection(), asyncio.start_server() |
   | Network: TCP & UDP     | Protocol                                                                      |
   | Network: transports    | BaseTransport                                                                 |
   - The streams API gives you the simplest way to handle socket communication over a network.
** Tasks and Futures
   - Future :: A *Future* represents a future completion state of some activity and is managed by the loop.
     - Useful APIs: ~set_result()~, ~result()~, ~cancel()~, ~cancelled()~, ~add_done_callback()~
 Future .
   - Task :: A subclass of *Future*, wrapper for coroutine objects. It provides all of he functionality for interaction with the loop. (more common)

*** ~ensure_future~ and ~create_task~
    - ~asyncio.ensure_future()~ is not a clear API, leads to misunderstanding about the asyncio library.
      - If you pass in a coroutine, it will produce a Task instance(scheduled). (just what ~create_task~ does)
      - If you pass a *Future* instance (also *Task* instance), you get the same *Future* instance.
      - The only time when you should be calling ~ensure_future()~ is when you are providing an API that accepts either a coroutine or a Future/Task(i.e. Awaitable). --Guido
      - asyncio.ensure_future() is a helper function intended for framework designers.

** Async Context Manager
   Convenient way to implement *setup and teardown*, also *RAII*.
*** Class Example
   #+begin_src python
     class Connection:
         def __init__(self, host, port):
             self._host = host
             self._port = port

         async def __aenter__(self):
             self.conn = await get_conn(self.host, self.port)
             return self.conn

         async def __aexit__(self, exc_type, exc, tb):
             await self.conn.close()

     async with Connection("localhost", 9001) as conn:
         ...
   #+end_src

*** Decorator Example
   - uses ~@contextlib.asynccontextmanager~ to create *simple* async context managers.
   #+begin_src python
     from contextlib import contextmanager, asynccontextmanager

     @contextmanager
     def web_page(url):
         data = download_webpage(url)
         yield data
         update_stats(url)

     with web_page('google.com') as data:
         process(data)

     @asynccontextmanager
     async def async_web_page(url):
         data = await download_webpage(url)
         yield data
         await update_stats(url)

     async with web_page('google.com') as data:
         process(data)
   #+end_src

*** Innovative Way to Wrap Blocking Functions
    #+begin_src python
      from contextlib import asynccontextmanager


      @asynccontextmanager
      async def async_web_page(url):
          loop = asyncio.get_event_loop()
          data = await loop.run_in_executor(None, download_webpage, url) # set None to use ThreadPoolExecutor
          yield data
          await loop.run_in_executor(None, update_stats, url)

      async with web_page('google.com') as data:
          process(data)
    #+end_src

** Async Iterators
   #+begin_src python
     class OneAtATime:
         def __init__(self, redis, keys):
             self._redis = redis
             self._keys = keys

         def __aiter__(self):
             self.ikeys = iter(self.keys)
             return self

         async def __next__(self):
             try:
                 k = next(self.ikeys)
             except StopIteration:
                 raise StopAsyncIteration
             value = await redis.get(k)
             return value
   #+end_src

*** Async Generators
   Async generators are async def functions that have yield keywords inside them.
   #+begin_src python
     async def one_at_a_time(redis, keys):
         for k in keys:
             value = await redis.get(k)
             yield value
   #+end_src
*** Async Comprehensions
    #+begin_src python
      [x async for x in aiter]
      {x async for x in aiter}
      {x: x async for x in aiter}
    #+end_src

** Streams
*** TCP Server
    #+begin_src python
      import asyncio
      from asyncio import StreamReader, StreamWriter

      async def echo(reader: StreamReader, writer: StreamWriter):
          print("New Connection")
          try:
              while data := await reader.readline(): # := allows for assignment of variables within expressions
                  writer.write(data.upper())
                  await writer.drain()
              print("Leaving Connection")
          except asyncio.CancelledError:
              print("Connection dropped")
              # asyncio.create_task(send_log()) # don't do this

      async def main(host="127.0.0.1", port=8888):
          server = await asyncio.start_server(echo, host, port)
          async with server:
              await server.serve_forever()

      if __name__ == '__main__':
          asyncio.run(main())
    #+end_src
    Important: Should avoid creating new tasks inside ~CancelledError~ exception handlers. If you must, be sure to also
    await the new task or future inside the scope of the same function.

*** Message Queue
    A message queue service is a backend application that receives connections from other
    applications and passes messages between those connected services, often referred to
    as publishers and subscribers.
    - Broker's Responsibilities
      - Maintains persistent socket connections to multiple clients.
      - Receives messages from clients with a target channel name.
      - Delivers those messages to all other clients subscribed to that same channel name.
    - Build a Simplest Protocol
      1. TCP is not a message-based protocol, we need to create our own protocol. (simplest protocol: add size header)

    A toy message queue: =/codes/msgqueue=

    - *A key aspect* was the realization that sending and receiving data might be best handled in separate coroutines.
      - Queues can be very useful for moving data between those different coroutines and for providing buffering to decouple them.

* Third-party Libraries
** Twisted
   Twisted includes a huge number of high-quality protocol implementations. HTTP, XMPP, NNTP, IMAP, SSH, IPC, FTP, DNS, SMTP, POP3.
   - Support for asyncio in Twisted:
   #+begin_src python
     from time import ctime
     from twisted.internet import asyncioreactor

     asyncioreactor.install()
     from twisted.internet import reactor, defer, task


     async def main():
         for i in range(5):
             print(f"{ctime()} Hello {i}")
             await task.deferLater(reactor, 1, lambda: None)

     if __name__ == '__main__':
         defer.ensureDeferred(main())
         reactor.run()
   #+end_src

** Janus Queue
   The Janus queue provides a solution for communication between threads and coroutines.
   It exposes both APIs, a blocking one and an async one.
   #+begin_src python
     # janus_demo.py
     import asyncio
     import random
     import time
     import janus


     async def main():
         loop = asyncio.get_running_loop()
         queue = janus.Queue(loop=loop)
         future = loop.run_in_executor(None, data_source, queue)
         while (data := await queue.async_q.get()) is not None: # None is a sentinel
             print(f"Got {data} off queue")
         print("Done.")


     def data_source(queue):
         for i in range(10):
             r = random.randint(0, 4)
             time.sleep(r)
             queue.sync_q.put(r)
         queue.sync_q.put(None) # put sentinel


     asyncio.run(main())
   #+end_src
   - It's better to aim for having short executor jobs

** ~aiohttp~
   - Minimal Http Server
     #+begin_src python
       from aiohttp import web


       async def hello(request):
           return web.Response(text="Hello, world")


       if __name__ == "__main__":
           app = web.Application()
           app.router.add_get("/", hello)
           web.run_app(app, port=8080)
     #+end_src
     - The ~aiohttp~ hided loops, tasks from us, leaving a very clean API.

*** Web Scraping
    - ~Splash~ for javascript rendering. It can run in a Docker container and provides an API for rendering other sites.
    - =/codes/newsscraper=

** ZeroMQ
   - "Smart" Sockets
   - Management of message passing
   - Automatic Reconnection Logic (brokerless messaging)
   - ~PyZMQ~ added support for Asyncio

*** Why to Use ØMQ with Asyncio?
    - ØMQ provides sockets that are already asynchronous, in a way that is usable with threading
    - What is the point of using ØMQ with asyncio? The answer is cleaner code.

*** ZeroMQ Patterns
    - Request-reply :: Connects a set of clients to a set of services. This is a remote procedure call and *task distribution pattern*.
    - Pub-sub :: Connects a set of publishers to a set of subscribers. This is a *data distribution pattern*.
    - Pipeline :: Connects nodes in a fan-out/fan-in pattern that can have multiple steps and loops. This is a *parallel task distribution* and *collection pattern*.
    - Exclusive pair :: Connects two sockets exclusively. This is a pattern for connecting two threads in a process.

*** Work with Asyncio
    The key thing to understand is that our asyncio code is going to run in a single thread,
    which means that it's fine to handle different sockets in different coroutines.
    #+begin_src python
      # poller_aio.py
      import asyncio

      import zmq
      from zmq.asyncio import Context

      context = Context()


      async def do_receiver():
          receiver = context.socket(zmq.PULL)
          receiver.connect("tcp://localhost:5557")
          while message := await receiver.recv_json():
              print(f"Via PULL: {message}")


      async def do_subscriber():
          subscriber = context.socket(zmq.SUB)
          subscriber.connect("tcp://localhost:5556")
          subscriber.setsockopt_string(zmq.SUBSCRIBE, "")
          while message := await subscriber.recv_json():
              print(f"Via SUB: {message}")


      async def main():
          await asyncio.gather(
              do_receiver(),
              do_subscriber(),
          )


      if __name__ == "__main__":
          asyncio.run(main())
    #+end_src

*** Case Study: Application Performance Monitoring
    - Application layer:  A ØMQ "transmitting" socket to send performance metrics to a central server.
    - Collection layer: The central server will expose a ØMQ socket to collect the data from all the running application instances.
    - Visualization layer: A web page displays the collected data in a set of charts.
    - =/codes/perf_monitor=

** ~asyncpg~
*** Basic Use
    #+begin_src python
      import asyncio
      import asyncpg
      import datetime
      from util import Database


      async def main():
          async with Database("test", owner=True) as conn:
              # conn.execute
              # conn.fetchval
              # conn.fetchrow
              ...
    #+end_src

*** Advanced Use
    - Explore ~asyncpg.create_pool~

*** Case Study: Cache Invalidation
    #+begin_quote
    There are two hard things in computer science: cache invalidation, naming things, and off-by-one errors.
    -- Phil Karlton
    #+end_quote
    It's common practice to look at design options that can limit excessive
    interaction with the database. The most common option is to use caching
    to "remember" previously fetched database results and replay them when asked.

    Strategies:
    1. Each app instance has an in-memory cache of DB queries.
    1. When one writes new data to the database, the database alerts all of the connected app instances of the new data.
    1. Each app instance then updates its internal cache accordingly.

    PostgreSQL built-in support for event updates via the ~LISTEN~ and ~NOTIFY~ commands

* Other Hints
  - call ~asyncio.get_running_loop()~ inside an ~async def~ function.
  - If you need to feed data to one or more *long-running* coroutines, the best way to do that is with ~asyncio.Queue~.
  - ~from contextlib import suppress~ to suppress exceptions: ~with suppress(asyncio.CancelledError):~
  - The process of executing JavaScript to load their actual content, complete HTML output is called rendering.


* Links
  - [[https://www.pythonsheets.com/notes/python-asyncio.html][Asyncio pysheeet]]
